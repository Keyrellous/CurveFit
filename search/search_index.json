{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Curve Fit! Background CurveFit is a Python package for fitting curves using nonlinear mixed effects. It can be used to do only that if desired. However, due to its current usage for the IHME COVID-19 project , it has modules specifically for evaluating model performance out beyond the range of time observed in the data. Likewise, it has modules for creating uncertainty intervals based on out of sample performance. In our methods documentation we discuss the statistical methods for CurveFit . In our code documentation , we explain the core model code and also the extensions that allow for evaluating model performance and generating uncertainty intervals. NOTE: This documentation is currently under construction and being updated regularly. IHME COVID-19 Project For any IHME COVID-19 related inquiries, please contact covid19@healthdata.org . To see the IHME projections visualization, click here . To read the paper, click here . For FAQs, click here . Please note that this code base makes up only one part of the IHME COVID-19 projection process, in particular the COVID-19 deaths forecasting. Getting Started To clone the repository and get started, you can either do git clone https://github.com/ihmeuw-msca/CurveFit.git cd CurveFit python setup.py install or use make install . Maintainers Aleksandr Aravkin ( saravkin@uw.edu ) Peng Zheng ( zhengp@uw.edu ) Marlena Bannick ( mbannick@uw.edu )","title":"Home"},{"location":"#welcome-to-curve-fit","text":"","title":"Welcome to Curve Fit!"},{"location":"#background","text":"CurveFit is a Python package for fitting curves using nonlinear mixed effects. It can be used to do only that if desired. However, due to its current usage for the IHME COVID-19 project , it has modules specifically for evaluating model performance out beyond the range of time observed in the data. Likewise, it has modules for creating uncertainty intervals based on out of sample performance. In our methods documentation we discuss the statistical methods for CurveFit . In our code documentation , we explain the core model code and also the extensions that allow for evaluating model performance and generating uncertainty intervals. NOTE: This documentation is currently under construction and being updated regularly.","title":"Background"},{"location":"#ihme-covid-19-project","text":"For any IHME COVID-19 related inquiries, please contact covid19@healthdata.org . To see the IHME projections visualization, click here . To read the paper, click here . For FAQs, click here . Please note that this code base makes up only one part of the IHME COVID-19 projection process, in particular the COVID-19 deaths forecasting.","title":"IHME COVID-19 Project"},{"location":"#getting-started","text":"To clone the repository and get started, you can either do git clone https://github.com/ihmeuw-msca/CurveFit.git cd CurveFit python setup.py install or use make install .","title":"Getting Started"},{"location":"#maintainers","text":"Aleksandr Aravkin ( saravkin@uw.edu ) Peng Zheng ( zhengp@uw.edu ) Marlena Bannick ( mbannick@uw.edu )","title":"Maintainers"},{"location":"code/","text":"Map of the Code We first start by walking through the core curve fitting model , and then the extensions that make it possible for CurveFit to be used for forecasting over time including pipelines and predictive validity . Core Model curevefit.core Setting Up a Model The code for the core curve fitting model is curvefit.core.model.CurveModel . To initialize a CurveModel , you need a pandas data frame and information about what type of model you want to fit. It needs to know which columns represent what and some model parameters. df (pd.DataFrame) : data frame with all available information for the model col_t (str) : the column that indicates the independent variable col_obs (str) : the column that indicates the dependent variable col_covs (list{list{str}}) : list of lists of strings that indicate the covariates to use for each covariate col_group (str) : the column that indicates the group variable (even if you only have one group you must pass a column that indicates group membership) param_names (list{str}) : names of the parameters for your specific functional form (more in functions ) link_fun (list{function}) : list of link functions for each of the parameters var_link_fun (list{function}) : list of functions for the variables including fixed and random effects Here is an example of creating a CurveModel with a data frame where time is the independent variable, death_rate is the dependent variable, and group is a variable indicating which group an observation belongs to. In this example, we want to fit to the log erf functional form (see functions ) with identity link functions for each parameter and identity variable link functions for each parameter. In this example, no parameters have covariates besides an intercept column of 1's. from curvefit.core.model import CurveModel from curvefit.core.functions import log_erf model = CurveModel ( df = df , col_t = 'time' , col_obs = 'death_rate' , group = 'group' , col_covs = [[ 'intercept' ], [ 'intercept' ], [ 'intercept' ]], param_names = [ 'alpha' , 'beta' , 'p' ], link_fun = [ lambda x : x , lambda x : x , lambda x : x ], var_link_fun = [ lambda x : x , lambda x : x , lambda x : x ], fun = log_erf ) Functions The curvefit package has some built-in functions for curves to fit. However, this list is not exhaustive, and you may pass any callable function that takes in t (an independent variable) and params (a list of parameters) to the function to the CurveModel class for the fun argument. What you pass in for param_names in the CurveModel needs to match what the fun callable expects. The available built-in functions in curvefit.functions are: The Error Function erf : error function (Gauss error function) derf : derivative of the error function log_erf : log error function log_derf : log derivative of the erf function The Expit Function (inverse of the logit function) expit : expit function log_expit : log expit function Please see the functions for information about the parametrization of these functions and how they relate to COVID-19 modeling. Fitting a Model Once you have a model defined, the method fit_params fits the model. At minimum, the only information that model.fit_params needs is initial values for the fixed effects. But there are many optional arguments that you can pass to model.fit_params to inform the optimization process. Below we describe each of these optional arguments. The result of fit_params is stored in CurveModel.result and the parameter estimates in CurveModel.params . Gaussian Priors fe_gprior and re_gprior Each parameter may have an associated Gaussian prior. This is optional and can be passed in as a list of lists. This specification, referring to our example will put Gaussian priors with mean 0 and standard deviation 1. on the alpha parameter, mean 0 and standard deviation 1e-3 on the beta parameter and mean 5 and standard deviation 10. on the p parameter. model . fit_params ( fe_gprior = [[ 0 , 1. ], [ 0 , 1e-3 ], [ 5 , 10. ]]) Likewise, you may have random effects Gaussian priors using the argument re_gprior , which has the same shape as fe_gprior , but refers to the random effects. For the specifications of fixed and random effects, please see the methods . Constraints fe_bounds and re_bounds You can also include parameter constraints for each of the fixed effects and the random effects. They are included as a list of lists. This specification, referring to our example , will bound all of the fixed effects between 0 and 100. and the random effects between -1 and 1. model . fit_params ( fe_bounds = [[ 0. , 100. ], [ 0. , 100. ], [ 0. , 100. ]], re_bounds = [[ - 1. , 1. ], [ - 1. , 1. ], [ - 1. , 1. ]] ) If you do not want to include random effects, set the bounds to be exactly 0. Please see more information on constraints in the methods . Initialization The optimization routine will perform better with smart starting values for the parameters. Initial values for the fixed effects, fe_init , are required and is passed in as a numpy array of the same length as your parameters. The initial values for the random effects, re_init , are passed in as a numpy array ordered by the group name and parameters. For example, if you had two groups in the model, the following would initialize the fixed effects at 1., 1., 1., and the random effects at -0.5, -0.5, -0.5, for the first group and 0.5, 0.5, 0.5, for the second group. import numpy as np model . fit_params ( fe_init = np . array ([ 1. , 1. , 1. ]), re_init = np . array ([ - 0.5 , - 0.5 , - 0.5 , 0.5 , 0.5 , 0.5 ]) ) There is an optional flag, smart_initialize that if True will run a model individually for each group in the model and use their fixed effects estimates to inform the initial values for both fixed and random effects of the mixed model that you want to fit. Optimization The optimization uses scipy.optimize.minimize and the \"L-BFGS-B\" which has a list of options that you can pass to it. These keyword options can be passed to the minimize function using the options argument. For example, the following would perform a maximum of 500 iterations and require an objective function tolerance of 1e-10. model . fit_params ( options = { 'ftol' : 1e-10 , 'maxiter' : 500 } ) If you have indicated that you want the model to do smart initialization with smart_initialize = True , then you can optionally pass a dictionary of smart_init_options to override the options just for the group-specific initial fits. Otherwise it will use all of the options in both the group-specific and overall fits. Please see scipy.optimize.minimize for more options. Please see the methods for more information about the optimization procedure. Obtaining Predictions from a Model To obtain predictions from a model that has been fit, use the method CurveModel.predict . The predict function needs to know which values of the independent variable you want to predict for, which group you want to predict for, and optionally, which space you want to predict in. For example, you might want to predict in log_erf space but make predictions in log_derf space. This is only possible for functions that are related to one another (see the functions section). Continuing with our example , the following call would make predictions at times 0, 1, and 2, for group \"A\" . import numpy as np model . predict ( t = np . array ([ 0. , 1. , 2. ]), group_name = \"A\" ) Model Pipelines curvefit.pipelines Documentation coming soon Predictive Validity curvefit.pv Documentation coming soon","title":"Code"},{"location":"code/#map-of-the-code","text":"We first start by walking through the core curve fitting model , and then the extensions that make it possible for CurveFit to be used for forecasting over time including pipelines and predictive validity .","title":"Map of the Code"},{"location":"code/#core-model","text":"curevefit.core","title":"Core Model"},{"location":"code/#setting-up-a-model","text":"The code for the core curve fitting model is curvefit.core.model.CurveModel . To initialize a CurveModel , you need a pandas data frame and information about what type of model you want to fit. It needs to know which columns represent what and some model parameters. df (pd.DataFrame) : data frame with all available information for the model col_t (str) : the column that indicates the independent variable col_obs (str) : the column that indicates the dependent variable col_covs (list{list{str}}) : list of lists of strings that indicate the covariates to use for each covariate col_group (str) : the column that indicates the group variable (even if you only have one group you must pass a column that indicates group membership) param_names (list{str}) : names of the parameters for your specific functional form (more in functions ) link_fun (list{function}) : list of link functions for each of the parameters var_link_fun (list{function}) : list of functions for the variables including fixed and random effects Here is an example of creating a CurveModel with a data frame where time is the independent variable, death_rate is the dependent variable, and group is a variable indicating which group an observation belongs to. In this example, we want to fit to the log erf functional form (see functions ) with identity link functions for each parameter and identity variable link functions for each parameter. In this example, no parameters have covariates besides an intercept column of 1's. from curvefit.core.model import CurveModel from curvefit.core.functions import log_erf model = CurveModel ( df = df , col_t = 'time' , col_obs = 'death_rate' , group = 'group' , col_covs = [[ 'intercept' ], [ 'intercept' ], [ 'intercept' ]], param_names = [ 'alpha' , 'beta' , 'p' ], link_fun = [ lambda x : x , lambda x : x , lambda x : x ], var_link_fun = [ lambda x : x , lambda x : x , lambda x : x ], fun = log_erf )","title":"Setting Up a Model"},{"location":"code/#functions","text":"The curvefit package has some built-in functions for curves to fit. However, this list is not exhaustive, and you may pass any callable function that takes in t (an independent variable) and params (a list of parameters) to the function to the CurveModel class for the fun argument. What you pass in for param_names in the CurveModel needs to match what the fun callable expects. The available built-in functions in curvefit.functions are: The Error Function erf : error function (Gauss error function) derf : derivative of the error function log_erf : log error function log_derf : log derivative of the erf function The Expit Function (inverse of the logit function) expit : expit function log_expit : log expit function Please see the functions for information about the parametrization of these functions and how they relate to COVID-19 modeling.","title":"Functions"},{"location":"code/#fitting-a-model","text":"Once you have a model defined, the method fit_params fits the model. At minimum, the only information that model.fit_params needs is initial values for the fixed effects. But there are many optional arguments that you can pass to model.fit_params to inform the optimization process. Below we describe each of these optional arguments. The result of fit_params is stored in CurveModel.result and the parameter estimates in CurveModel.params .","title":"Fitting a Model"},{"location":"code/#gaussian-priors","text":"fe_gprior and re_gprior Each parameter may have an associated Gaussian prior. This is optional and can be passed in as a list of lists. This specification, referring to our example will put Gaussian priors with mean 0 and standard deviation 1. on the alpha parameter, mean 0 and standard deviation 1e-3 on the beta parameter and mean 5 and standard deviation 10. on the p parameter. model . fit_params ( fe_gprior = [[ 0 , 1. ], [ 0 , 1e-3 ], [ 5 , 10. ]]) Likewise, you may have random effects Gaussian priors using the argument re_gprior , which has the same shape as fe_gprior , but refers to the random effects. For the specifications of fixed and random effects, please see the methods .","title":"Gaussian Priors"},{"location":"code/#constraints","text":"fe_bounds and re_bounds You can also include parameter constraints for each of the fixed effects and the random effects. They are included as a list of lists. This specification, referring to our example , will bound all of the fixed effects between 0 and 100. and the random effects between -1 and 1. model . fit_params ( fe_bounds = [[ 0. , 100. ], [ 0. , 100. ], [ 0. , 100. ]], re_bounds = [[ - 1. , 1. ], [ - 1. , 1. ], [ - 1. , 1. ]] ) If you do not want to include random effects, set the bounds to be exactly 0. Please see more information on constraints in the methods .","title":"Constraints"},{"location":"code/#initialization","text":"The optimization routine will perform better with smart starting values for the parameters. Initial values for the fixed effects, fe_init , are required and is passed in as a numpy array of the same length as your parameters. The initial values for the random effects, re_init , are passed in as a numpy array ordered by the group name and parameters. For example, if you had two groups in the model, the following would initialize the fixed effects at 1., 1., 1., and the random effects at -0.5, -0.5, -0.5, for the first group and 0.5, 0.5, 0.5, for the second group. import numpy as np model . fit_params ( fe_init = np . array ([ 1. , 1. , 1. ]), re_init = np . array ([ - 0.5 , - 0.5 , - 0.5 , 0.5 , 0.5 , 0.5 ]) ) There is an optional flag, smart_initialize that if True will run a model individually for each group in the model and use their fixed effects estimates to inform the initial values for both fixed and random effects of the mixed model that you want to fit.","title":"Initialization"},{"location":"code/#optimization","text":"The optimization uses scipy.optimize.minimize and the \"L-BFGS-B\" which has a list of options that you can pass to it. These keyword options can be passed to the minimize function using the options argument. For example, the following would perform a maximum of 500 iterations and require an objective function tolerance of 1e-10. model . fit_params ( options = { 'ftol' : 1e-10 , 'maxiter' : 500 } ) If you have indicated that you want the model to do smart initialization with smart_initialize = True , then you can optionally pass a dictionary of smart_init_options to override the options just for the group-specific initial fits. Otherwise it will use all of the options in both the group-specific and overall fits. Please see scipy.optimize.minimize for more options. Please see the methods for more information about the optimization procedure.","title":"Optimization"},{"location":"code/#obtaining-predictions-from-a-model","text":"To obtain predictions from a model that has been fit, use the method CurveModel.predict . The predict function needs to know which values of the independent variable you want to predict for, which group you want to predict for, and optionally, which space you want to predict in. For example, you might want to predict in log_erf space but make predictions in log_derf space. This is only possible for functions that are related to one another (see the functions section). Continuing with our example , the following call would make predictions at times 0, 1, and 2, for group \"A\" . import numpy as np model . predict ( t = np . array ([ 0. , 1. , 2. ]), group_name = \"A\" )","title":"Obtaining Predictions from a Model"},{"location":"code/#model-pipelines","text":"curvefit.pipelines Documentation coming soon","title":"Model Pipelines"},{"location":"code/#predictive-validity","text":"curvefit.pv Documentation coming soon","title":"Predictive Validity"},{"location":"methods/","text":"Overview CurveFit is an extendable nonlinear mixed effects model for fitting curves. The main application in this development is COVID-19 forecasting, so that the curves we consider are variants of logistic models. However the interface allows any user-specified parametrized family. Parametrized curves have several key features that make them useful for forecating: We can capture key signals from noisy data. Parameters are interpretable, and can be modeled using covariates in a transparent way. Parametric forms allow for more stable inversion approaches, for current and future work. Parametric functions impose rigid assumptions that make forecasting more stable. COVID-19 functional forms We considered two functional forms so far when modeling the COVID-19 epidemic. Generalized Logistic: f(t; \\alpha, \\beta, p) = \\frac{p}{1 + \\exp(-\\alpha(t-\\beta))} Generalized Gaussian Error Function f(t; \\alpha, \\beta, p) = \\frac{p}{2}\\left(\\Psi(\\alpha(t-\\beta)\\right) = \\frac{p}{2}\\left(1+ \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{\\alpha(t-\\beta)} \\exp\\left(-\\tau^2\\right)d\\tau\\right) Each form has comparable fundamental parameters: Level p : Controls the ultimate level. Slope \\alpha : Controls speed of infection. Inflection \\beta : Time at which the rate of change is maximal. We can fit these parameters to data, but this by itself does not account for covariates, and cannot connect different locations together. The next section therefore specifies statistical models that do this. Statistical Model Statistical assumptions link covariates across locations. Key aspects are the following: Parameters may be influenced by covariates, e.g. those that reflect social distancing Parameters may be modeled in a different space, e.g. p, \\alpha are non-negative Parameters and covariate multipliers may be location-specific, with assumptions placed on their variation. CurveFit specification is tailored to these three requirements. Every parameter in any functional form can be specified through a link function, covariates, fixed, and random effects. The final estimation problem is a nonlinear mixed effects model, with user-specified priors on fixed and random effects. For example, consider the ERF functional form with covariates \\alpha, \\beta, p . Assume we are fitting data in log-cumulative-death-rate space. Input data are: S_j : social distancing covariate value at location j y_j^t : cumulative death rate in location j at time t We specify the statistical model as follows: Measurement model: \\begin{aligned} \\log(y_j^t) &= \\frac{p_j}{2}\\left(1+ \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{\\alpha_j(t-\\beta_j)} \\exp\\left(-\\tau^2\\right)d\\tau\\right) + \\epsilon_{t,j} \\\\ \\epsilon_{t,j} & \\sim N(0, V_t) \\end{aligned} \\beta -model specification: \\begin{aligned} \\beta_j &= \\beta + \\gamma_j S_j + \\epsilon_j^\\beta \\\\ \\gamma_j &\\sim N(\\overline \\gamma, V_\\gamma) \\\\ \\epsilon_j^\\beta &\\sim N(0, V_\\beta) \\end{aligned} \\alpha -model specification: \\begin{aligned} \\alpha_j &= \\exp(\\alpha + u_j^\\alpha) \\\\ u_{\\alpha, j} & \\sim N(0, V_\\alpha) \\end{aligned} p -model specification: \\begin{aligned} p_j & = \\exp(p + u_j^p) \\\\ u_{p,j} & \\sim N(0, V_p) \\end{aligned} In this example, the user specifies prior mean \\overline \\gamma variance parameters V_t, V_\\gamma, V_\\beta, V_\\alpha, V_p . CurveFit estimates: fixed effects \\alpha, \\beta, p random effects \\{\\gamma_j, u_j^\\alpha, u_j^\\beta, u_j^p\\} Exponential link functions are used to model non-negative parameters \\alpha, p . Constraints Simple bound constraints on parameters can be used to make the model more robust. For any fixed or random effect, the user can enter simple bound constraints of the form L \\leq \\theta \\leq U. The parameters returned by CurveFit are guaranteed to satisfy these simple bounds. Optimization Procedure The optimization problem we obtain from specifying functional forms, priors, and constraints on all parameters is a bound-constrained nonlinear least squares problem. We explain the solver, derivative computation, and initialization procedure below. Solver We solve the problem using L-BFGS-B . The L-BFGS-B algorithm uses gradients to build a Hessian approximation, and efficiently uses that approximation and projected gradient method onto the bound constraints to identify parameter spaces over which solutions can be efficiently found, see the paper . It is a standard and robust algorithm that's well suited to the task. Derivatives We do not explicitly compute derivatives of the nonlinear least squares objective induced from the problem specification. Instead, we use the complex step method to do this. The complex step method is a simple example of Automatic Differentiation , that is, it can provide machine precision derivatives at the cost of a function evaluation. This is very useful given the flexibility on functional forms. Uncertainty Currently CurveFit uses model-based uncertainty, with out-of-sample approaches under development. Predictive Validity-Based Uncertainty Documentation coming soon Model-Based Uncertainty We partition model-based uncertainty into estimates coming from fixed and random components. Fixed effects capture the variation of the mean effects, and random effects uncertainty captures the variation across locations. Fixed Effects For any estimator obtained by solving a nonlinear least squares problem, we can use the Fisher information matrix to get an asymptotic approximation to the uncertainty. Let \\hat{ \\theta} = \\arg\\min_{ \\theta} := \\frac{1}{2}\\theta^T W^{-1} \\theta + \\frac{1}{2 \\sigma^2} \\|\\Sigma^{-1/2} (y - f( \\theta; X))\\|^2 where W is any prior variance and \\Sigma is the variance of observations. Then our approximation for the variance matrix of the estimate is given by V(\\hat \\theta) = \\mathcal{I}(\\theta)^{-1} = \\left(J_{\\hat \\theta}^T \\Sigma^{-1} J_{\\hat \\theta} + W^{-1} \\right)^{-1} where J_{\\hat{ \\theta}} := \\nabla_{ \\theta} f( \\theta; X) is the Jacobian matrix evaluated at \\theta = \\hat \\theta . The Jacobian is also computed using the complex step method. Random effects To obtain the variance of the random effects, we derive an empirical variance matrix across locations. Given a set of zero mean random effect estimates \\{v_j\\} , with each v_j a vector of k of random effect types, we get an empirical matrix V_0 \\in \\mathbb{R}^{k\\times k} by V_0 = \\frac{1}{n}\\sum_{j=1}^N v_j v_j^T To obtain posterior uncertainty for each specific location, we use the empirical V_0 as a prior, and any data at the location as the measurement model, and re-fit the location: \\hat{ \\theta}_i = \\arg\\min_{ \\theta} := \\frac{1}{2}\\theta_i^T V_0^{-1}\\theta_i + \\frac{1}{2 \\sigma^2} \\| \\Sigma_i^{-1/2}(y_i - f_i( \\theta_i; X_i))\\|^2 Within each location, this is analogous to the fixed effects analysis. The location-specific uncertainty is then estimated from the same Fisher information analysis: V_i({\\hat \\theta}) = ( J_i^T \\Sigma_i ^{-1} J_i + V_0^{-1})^{-1}.","title":"Methods"},{"location":"methods/#overview","text":"CurveFit is an extendable nonlinear mixed effects model for fitting curves. The main application in this development is COVID-19 forecasting, so that the curves we consider are variants of logistic models. However the interface allows any user-specified parametrized family. Parametrized curves have several key features that make them useful for forecating: We can capture key signals from noisy data. Parameters are interpretable, and can be modeled using covariates in a transparent way. Parametric forms allow for more stable inversion approaches, for current and future work. Parametric functions impose rigid assumptions that make forecasting more stable.","title":"Overview"},{"location":"methods/#covid-19-functional-forms","text":"We considered two functional forms so far when modeling the COVID-19 epidemic. Generalized Logistic: f(t; \\alpha, \\beta, p) = \\frac{p}{1 + \\exp(-\\alpha(t-\\beta))} Generalized Gaussian Error Function f(t; \\alpha, \\beta, p) = \\frac{p}{2}\\left(\\Psi(\\alpha(t-\\beta)\\right) = \\frac{p}{2}\\left(1+ \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{\\alpha(t-\\beta)} \\exp\\left(-\\tau^2\\right)d\\tau\\right) Each form has comparable fundamental parameters: Level p : Controls the ultimate level. Slope \\alpha : Controls speed of infection. Inflection \\beta : Time at which the rate of change is maximal. We can fit these parameters to data, but this by itself does not account for covariates, and cannot connect different locations together. The next section therefore specifies statistical models that do this.","title":"COVID-19 functional forms"},{"location":"methods/#statistical-model","text":"Statistical assumptions link covariates across locations. Key aspects are the following: Parameters may be influenced by covariates, e.g. those that reflect social distancing Parameters may be modeled in a different space, e.g. p, \\alpha are non-negative Parameters and covariate multipliers may be location-specific, with assumptions placed on their variation. CurveFit specification is tailored to these three requirements. Every parameter in any functional form can be specified through a link function, covariates, fixed, and random effects. The final estimation problem is a nonlinear mixed effects model, with user-specified priors on fixed and random effects. For example, consider the ERF functional form with covariates \\alpha, \\beta, p . Assume we are fitting data in log-cumulative-death-rate space. Input data are: S_j : social distancing covariate value at location j y_j^t : cumulative death rate in location j at time t We specify the statistical model as follows: Measurement model: \\begin{aligned} \\log(y_j^t) &= \\frac{p_j}{2}\\left(1+ \\frac{2}{\\sqrt{\\pi}}\\int_{0}^{\\alpha_j(t-\\beta_j)} \\exp\\left(-\\tau^2\\right)d\\tau\\right) + \\epsilon_{t,j} \\\\ \\epsilon_{t,j} & \\sim N(0, V_t) \\end{aligned} \\beta -model specification: \\begin{aligned} \\beta_j &= \\beta + \\gamma_j S_j + \\epsilon_j^\\beta \\\\ \\gamma_j &\\sim N(\\overline \\gamma, V_\\gamma) \\\\ \\epsilon_j^\\beta &\\sim N(0, V_\\beta) \\end{aligned} \\alpha -model specification: \\begin{aligned} \\alpha_j &= \\exp(\\alpha + u_j^\\alpha) \\\\ u_{\\alpha, j} & \\sim N(0, V_\\alpha) \\end{aligned} p -model specification: \\begin{aligned} p_j & = \\exp(p + u_j^p) \\\\ u_{p,j} & \\sim N(0, V_p) \\end{aligned} In this example, the user specifies prior mean \\overline \\gamma variance parameters V_t, V_\\gamma, V_\\beta, V_\\alpha, V_p . CurveFit estimates: fixed effects \\alpha, \\beta, p random effects \\{\\gamma_j, u_j^\\alpha, u_j^\\beta, u_j^p\\} Exponential link functions are used to model non-negative parameters \\alpha, p .","title":"Statistical Model"},{"location":"methods/#constraints","text":"Simple bound constraints on parameters can be used to make the model more robust. For any fixed or random effect, the user can enter simple bound constraints of the form L \\leq \\theta \\leq U. The parameters returned by CurveFit are guaranteed to satisfy these simple bounds.","title":"Constraints"},{"location":"methods/#optimization-procedure","text":"The optimization problem we obtain from specifying functional forms, priors, and constraints on all parameters is a bound-constrained nonlinear least squares problem. We explain the solver, derivative computation, and initialization procedure below.","title":"Optimization Procedure"},{"location":"methods/#solver","text":"We solve the problem using L-BFGS-B . The L-BFGS-B algorithm uses gradients to build a Hessian approximation, and efficiently uses that approximation and projected gradient method onto the bound constraints to identify parameter spaces over which solutions can be efficiently found, see the paper . It is a standard and robust algorithm that's well suited to the task.","title":"Solver"},{"location":"methods/#derivatives","text":"We do not explicitly compute derivatives of the nonlinear least squares objective induced from the problem specification. Instead, we use the complex step method to do this. The complex step method is a simple example of Automatic Differentiation , that is, it can provide machine precision derivatives at the cost of a function evaluation. This is very useful given the flexibility on functional forms.","title":"Derivatives"},{"location":"methods/#uncertainty","text":"Currently CurveFit uses model-based uncertainty, with out-of-sample approaches under development.","title":"Uncertainty"},{"location":"methods/#predictive-validity-based-uncertainty","text":"Documentation coming soon","title":"Predictive Validity-Based Uncertainty"},{"location":"methods/#model-based-uncertainty","text":"We partition model-based uncertainty into estimates coming from fixed and random components. Fixed effects capture the variation of the mean effects, and random effects uncertainty captures the variation across locations. Fixed Effects For any estimator obtained by solving a nonlinear least squares problem, we can use the Fisher information matrix to get an asymptotic approximation to the uncertainty. Let \\hat{ \\theta} = \\arg\\min_{ \\theta} := \\frac{1}{2}\\theta^T W^{-1} \\theta + \\frac{1}{2 \\sigma^2} \\|\\Sigma^{-1/2} (y - f( \\theta; X))\\|^2 where W is any prior variance and \\Sigma is the variance of observations. Then our approximation for the variance matrix of the estimate is given by V(\\hat \\theta) = \\mathcal{I}(\\theta)^{-1} = \\left(J_{\\hat \\theta}^T \\Sigma^{-1} J_{\\hat \\theta} + W^{-1} \\right)^{-1} where J_{\\hat{ \\theta}} := \\nabla_{ \\theta} f( \\theta; X) is the Jacobian matrix evaluated at \\theta = \\hat \\theta . The Jacobian is also computed using the complex step method. Random effects To obtain the variance of the random effects, we derive an empirical variance matrix across locations. Given a set of zero mean random effect estimates \\{v_j\\} , with each v_j a vector of k of random effect types, we get an empirical matrix V_0 \\in \\mathbb{R}^{k\\times k} by V_0 = \\frac{1}{n}\\sum_{j=1}^N v_j v_j^T To obtain posterior uncertainty for each specific location, we use the empirical V_0 as a prior, and any data at the location as the measurement model, and re-fit the location: \\hat{ \\theta}_i = \\arg\\min_{ \\theta} := \\frac{1}{2}\\theta_i^T V_0^{-1}\\theta_i + \\frac{1}{2 \\sigma^2} \\| \\Sigma_i^{-1/2}(y_i - f_i( \\theta_i; X_i))\\|^2 Within each location, this is analogous to the fixed effects analysis. The location-specific uncertainty is then estimated from the same Fisher information analysis: V_i({\\hat \\theta}) = ( J_i^T \\Sigma_i ^{-1} J_i + V_0^{-1})^{-1}.","title":"Model-Based Uncertainty"},{"location":"updates/","text":"","title":"Release Notes"}]}